{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Copy of Xray_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaitumart/Chexpert/blob/master/Copy_of_Xray_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb3y7YkMJ7ek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import os\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from random import random\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QtUJHJsJ7eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class XrayDataset(Dataset):\n",
        "    def __init__(self, data_dir, train=True, convertRGB=False):\n",
        "        sample_file = \"valid.csv\"\n",
        "        sample_folder = \"valid\"\n",
        "        self.train = train\n",
        "        if train:\n",
        "            sample_file = \"train.csv\"\n",
        "            sample_folder = \"train\"\n",
        "        self.sample_file = os.path.join(data_dir, sample_file)\n",
        "        self.sample_folder = os.path.join(data_dir, sample_folder)\n",
        "        self.convertRGB = convertRGB\n",
        "\n",
        "        self.labels = []\n",
        "        self.paths = []\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(240),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            \n",
        "        ])\n",
        "\n",
        "        with open(self.sample_file) as f:\n",
        "            f = [line for line in f if random() <= .01]\n",
        "            for line in f:\n",
        "                if line.startswith(\"Path\"):\n",
        "                    continue\n",
        "                parts = line.split(\",\")\n",
        "                self.paths.append(os.path.join(data_dir, \"..\", parts[0]))\n",
        "                multi_label = []\n",
        "                for i in parts[5:]:\n",
        "                    if i.strip() == \"\" or int(float(i.strip())) == -1:\n",
        "                        multi_label.append(0)\n",
        "                    else:\n",
        "                        multi_label.append((int(float(i.strip()))))\n",
        "                self.labels.append(multi_label)\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.train:\n",
        "            return int(len(self.paths) / 8)\n",
        "        else:\n",
        "            return int(len(self.paths))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        #print(self.paths[index])\n",
        "        if self.convertRGB:\n",
        "            image = Image.open(self.paths[index]).convert('RGB')\n",
        "        else:\n",
        "            image = Image.open(self.paths[index])\n",
        "        image = self.transform(image)\n",
        "\n",
        "        X = image #torch.load(self.paths[index])\n",
        "        #y = torch.LongTensor(self.labels[index])\n",
        "        y = torch.FloatTensor([self.labels[index][6],self.labels[index][8],self.labels[index][10]]) # 10 = Pleural Effusion target AUC of (0.97)\n",
        "\n",
        "        return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udFfpS-xJ7eq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training settings\n",
        "batch_size=32 \n",
        "epochs=10\n",
        "log_interval=10\n",
        "lr=0.001\n",
        "momentum=0.5\n",
        "no_cuda=False \n",
        "save_model=False\n",
        "seed=1\n",
        "test_batch_size=1000\n",
        "number_of_classes = 3 # all classes is 14\n",
        "model_to_use = \"densenet\"\n",
        "freeze_pretrained = True\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRIXz8bnJ7es",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data\n",
        "use_cuda = not no_cuda and torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    print(\"Using \" + torch.cuda.get_device_name(0))\n",
        "    torch.cuda.set_device(0)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "# lets fix the random seeds for reproducibility.\n",
        "torch.manual_seed(6250)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(6250)\n",
        "\n",
        "kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "if model_to_use == \"densenet\":\n",
        "    rgb = True\n",
        "else:\n",
        "    rgb = False\n",
        "\n",
        "train_dataset = XrayDataset(\"C:/Users/chait/Downloads/CheXpert-v1.0-small/CheXpert-v1.0-small\", True,convertRGB=rgb)\n",
        "test_dataset = XrayDataset(\"C:/Users/chait/Downloads/CheXpert-v1.0-small/CheXpert-v1.0-small\", False,convertRGB=rgb)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                               batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                              batch_size=batch_size, shuffle=True, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NiG0EZLJ7eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define NN\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(57*57*50, 500)# in_features=64*9*9\n",
        "        #self.fc1 = nn.Linear(224*224, 500)\n",
        "        self.fc2 = nn.Linear(500, number_of_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 57*57*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def train(model, device, train_loader, criterion, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                       100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test(model, device, criterion, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    outputs = []\n",
        "    targets = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target)\n",
        "            pred = (output > 0.5).float()\n",
        "            outputs.extend(output.tolist())\n",
        "            targets.extend(target.tolist())\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    aucs = calc_auc_roc(np.asarray(outputs), np.asarray(targets))\n",
        "    print(\"AUC: \" + \" \".join(str(x) for x in aucs.values()))\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, (len(test_loader.dataset) * number_of_classes),\n",
        "        100. * correct / (len(test_loader.dataset) * number_of_classes)))\n",
        "    return aucs.values()\n",
        "\n",
        "def calc_auc_roc(outputs, targets):\n",
        "    aucs = {}\n",
        "    for i in range(number_of_classes):\n",
        "        t1 = targets[:, i]\n",
        "        o1 = outputs[:, i]\n",
        "        fpr, tpr, thresholds = roc_curve(t1, o1)\n",
        "        aucs[i] = auc(fpr, tpr)\n",
        "    return aucs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mkxxrppJ7ew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if model_to_use == \"densenet\":\n",
        "        model = torchvision.models.densenet121(pretrained=True).to(device)\n",
        "        if freeze_pretrained:\n",
        "            for param in model.parameters():\n",
        "                param.requires_grad = False\n",
        "        #model = torchvision.models.resnet152(pretrained=True).to(device)\n",
        "        #model = torchvision.models.densenet121(pretrained='imagenet').to(device)\n",
        "        num_ftrs = model.classifier.in_features # model.fc for resnet, model.classifier for densenet\n",
        "        model.classifier = nn.Linear(num_ftrs, number_of_classes)\n",
        "else:\n",
        "        model = Net().to(device)\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "    \n",
        "#optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "0JDOY9vOJ7ey",
        "colab_type": "code",
        "outputId": "5d52c263-a4a7-4332-ecae-aac83225a607",
        "colab": {}
      },
      "source": [
        "best_aucs = [0] * number_of_classes\n",
        "best_avg_auc = 0\n",
        "decreasing_auc_epoch_count = 0\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "        train(model, device, train_loader, criterion, optimizer, epoch)\n",
        "        aucs = test(model, device, criterion, test_loader)\n",
        "        avg_auc = sum(aucs) / len(aucs)\n",
        "        if avg_auc > best_avg_auc:\n",
        "            best_avg_auc = avg_auc\n",
        "            best_aucs = aucs\n",
        "            decreasing_auc_epoch_count = 0\n",
        "        else:\n",
        "            decreasing_auc_epoch_count += 1\n",
        "            if decreasing_auc_epoch_count > 3:\n",
        "                print(\"Exiting training early, AUC not increasing. Exited on epoch \" + str(epoch))\n",
        "                break\n",
        "if (save_model):\n",
        "    torch.save(model.state_dict(),\"model.pt\")\n",
        "    \n",
        "best_aucs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/276 (0%)]\tLoss: 0.659778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\chait\\Anaconda3\\envs\\hw5\\lib\\site-packages\\sklearn\\metrics\\ranking.py:659: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  UndefinedMetricWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUC: nan 0.0 nan\n",
            "\n",
            "Test set: Average loss: 0.3419, Accuracy: 5/6 (83%)\n",
            "\n",
            "Train Epoch: 2 [0/276 (0%)]\tLoss: 0.653974\n",
            "AUC: nan 0.0 nan\n",
            "\n",
            "Test set: Average loss: 0.2889, Accuracy: 5/6 (83%)\n",
            "\n",
            "Train Epoch: 3 [0/276 (0%)]\tLoss: 0.387167\n",
            "AUC: nan 0.0 nan\n",
            "\n",
            "Test set: Average loss: 0.2600, Accuracy: 5/6 (83%)\n",
            "\n",
            "Train Epoch: 4 [0/276 (0%)]\tLoss: 0.465479\n",
            "AUC: nan 0.0 nan\n",
            "\n",
            "Test set: Average loss: 0.2953, Accuracy: 5/6 (83%)\n",
            "\n",
            "Exiting training early, AUC not increasing. Exited on epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOmBXNnrJ7e1",
        "colab_type": "code",
        "outputId": "31aba6b7-5c2e-4b9d-8f50-d6d3fc17cce8",
        "colab": {}
      },
      "source": [
        "sample_file = os.path.join(\"C:/Users/chait/Downloads/CheXpert-v1.0-small/CheXpert-v1.0-small/train.csv\")\n",
        "sample_folder = os.path.join(\"C:/Users/chait/Downloads/CheXpert-v1.0-small/CheXpert-v1.0-small/train\")\n",
        "import pandas as pd\n",
        "sample_table = pd.read_csv(sample_file, keep_default_na=True)\n",
        "sample_table['patient_id'] =  sample_table['Path'].str.split('/').str[2]\n",
        "sample_table['study_id'] =  sample_table['Path'].str.split('/').str[3]\n",
        "\n",
        "sample_table.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Path</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Frontal/Lateral</th>\n",
              "      <th>AP/PA</th>\n",
              "      <th>No Finding</th>\n",
              "      <th>Enlarged Cardiomediastinum</th>\n",
              "      <th>Cardiomegaly</th>\n",
              "      <th>Lung Opacity</th>\n",
              "      <th>Lung Lesion</th>\n",
              "      <th>...</th>\n",
              "      <th>Consolidation</th>\n",
              "      <th>Pneumonia</th>\n",
              "      <th>Atelectasis</th>\n",
              "      <th>Pneumothorax</th>\n",
              "      <th>Pleural Effusion</th>\n",
              "      <th>Pleural Other</th>\n",
              "      <th>Fracture</th>\n",
              "      <th>Support Devices</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>study_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient00001/study1/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>68</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>patient00001</td>\n",
              "      <td>study1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient00002/study2/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>87</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>patient00002</td>\n",
              "      <td>study2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>83</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>patient00002</td>\n",
              "      <td>study1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>83</td>\n",
              "      <td>Lateral</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>patient00002</td>\n",
              "      <td>study1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient00003/study1/...</td>\n",
              "      <td>Male</td>\n",
              "      <td>41</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>patient00003</td>\n",
              "      <td>study1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Path     Sex  Age  \\\n",
              "0  CheXpert-v1.0-small/train/patient00001/study1/...  Female   68   \n",
              "1  CheXpert-v1.0-small/train/patient00002/study2/...  Female   87   \n",
              "2  CheXpert-v1.0-small/train/patient00002/study1/...  Female   83   \n",
              "3  CheXpert-v1.0-small/train/patient00002/study1/...  Female   83   \n",
              "4  CheXpert-v1.0-small/train/patient00003/study1/...    Male   41   \n",
              "\n",
              "  Frontal/Lateral AP/PA  No Finding  Enlarged Cardiomediastinum  Cardiomegaly  \\\n",
              "0         Frontal    AP         1.0                         NaN           NaN   \n",
              "1         Frontal    AP         NaN                         NaN          -1.0   \n",
              "2         Frontal    AP         NaN                         NaN           NaN   \n",
              "3         Lateral   NaN         NaN                         NaN           NaN   \n",
              "4         Frontal    AP         NaN                         NaN           NaN   \n",
              "\n",
              "   Lung Opacity  Lung Lesion  ...  Consolidation  Pneumonia  Atelectasis  \\\n",
              "0           NaN          NaN  ...            NaN        NaN          NaN   \n",
              "1           1.0          NaN  ...           -1.0        NaN         -1.0   \n",
              "2           1.0          NaN  ...           -1.0        NaN          NaN   \n",
              "3           1.0          NaN  ...           -1.0        NaN          NaN   \n",
              "4           NaN          NaN  ...            NaN        NaN          NaN   \n",
              "\n",
              "   Pneumothorax  Pleural Effusion  Pleural Other  Fracture  Support Devices  \\\n",
              "0           0.0               NaN            NaN       NaN              1.0   \n",
              "1           NaN              -1.0            NaN       1.0              NaN   \n",
              "2           NaN               NaN            NaN       1.0              NaN   \n",
              "3           NaN               NaN            NaN       1.0              NaN   \n",
              "4           0.0               NaN            NaN       NaN              NaN   \n",
              "\n",
              "     patient_id study_id  \n",
              "0  patient00001   study1  \n",
              "1  patient00002   study2  \n",
              "2  patient00002   study1  \n",
              "3  patient00002   study1  \n",
              "4  patient00003   study1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S6_dxk2J7e3",
        "colab_type": "code",
        "outputId": "4c2f6751-5484-4612-d70a-dbb24e44cf0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "\n",
        "\n",
        "paths = []\n",
        "\n",
        "with open(sample_file) as f:\n",
        "            f = [line for line in f if random() <= .01]\n",
        "            for line in f:\n",
        "                if line.startswith(\"Path\"):\n",
        "                    continue\n",
        "                parts = line.split(\",\")\n",
        "                paths.append(os.path.join(\"C:/Users/chait/Downloads/CheXpert-v1.0-small/CheXpert-v1.0-small\", \"..\", parts[0]))\n",
        "              \n",
        "print(paths[0]) \n",
        "print(len(paths))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-567e6b6ae667>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m.01\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sample_file' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKnxuK7PJ7e5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class XrayDataset(Dataset):\n",
        "    def __init__(self, data_dir, train=True, convertRGB=False):\n",
        "        sample_file = \"valid.csv\"\n",
        "        sample_folder = \"valid\"\n",
        "        self.train = train\n",
        "        if train:\n",
        "            sample_file = \"train.csv\"\n",
        "            sample_folder = \"train\"\n",
        "        self.sample_file = os.path.join(data_dir, sample_file)\n",
        "        self.sample_folder = os.path.join(data_dir, sample_folder)\n",
        "        self.convertRGB = convertRGB\n",
        "\n",
        "        self.labels = []\n",
        "        self.paths = []\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(240),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            \n",
        "        ])\n",
        "\n",
        "        with open(self.sample_file) as f:\n",
        "            f = [line for line in f if random() <= .01]\n",
        "            for line in f:\n",
        "                if line.startswith(\"Path\"):\n",
        "                    continue\n",
        "                parts = line.split(\",\")\n",
        "                self.paths.append(os.path.join(data_dir, \"..\", parts[0]))\n",
        "                multi_label = []\n",
        "                for i in parts[5:]:\n",
        "                    if i.strip() == \"\" or int(float(i.strip())) == -1:\n",
        "                        multi_label.append(0)\n",
        "                    else:\n",
        "                        multi_label.append((int(float(i.strip()))))\n",
        "                self.labels.append(multi_label)\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.train:\n",
        "            return int(len(self.paths) / 8)\n",
        "        else:\n",
        "            return int(len(self.paths))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        #print(self.paths[index])\n",
        "        if self.convertRGB:\n",
        "            image = Image.open(self.paths[index]).convert('RGB')\n",
        "        else:\n",
        "            image = Image.open(self.paths[index])\n",
        "        image = self.transform(image)\n",
        "\n",
        "        X = image #torch.load(self.paths[index])\n",
        "        #y = torch.LongTensor(self.labels[index])\n",
        "        y = torch.FloatTensor([self.labels[index][6],self.labels[index][8],self.labels[index][10]]) # 10 = Pleural Effusion target AUC of (0.97)\n",
        "\n",
        "        return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXNpg5b4J7e7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(train_loader)\n",
        "X_samples, y_samples = dataiter.next()\n",
        "\n",
        "print(X_samples)\n",
        "print(y_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulS99wduR8T5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "image = Image.open('gdrive/My Drive/chestxray/CheXpert-v1.0-small/train/patient45852/study3/view1_frontal.jpg')\n",
        "print(image)\n",
        "#image.show()\n",
        "image1 = image.resize((200,200),Image.LANCZOS)\n",
        "plt.imshow(image1)\n",
        "print(image1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}